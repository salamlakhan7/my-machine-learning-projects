# -*- coding: utf-8 -*-
"""1_Loan_Data_RF_Classification_Supervised.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HTsjPQKT2vxERpEzacWz0IAv_IntPI9m
"""

import pandas as pd
loan_data = pd.read_csv("/content/loan_data.csv")
print(loan_data.shape)
loan_data.head(100)

import matplotlib.pyplot as plt
# Helper function for data distribution
# Visualize the proportion of borrowers
def show_loan_distrib(data):
  count = ""
  if isinstance(data, pd.DataFrame):
      count = data["not.fully.paid"].value_counts()
  else:
      count = data.value_counts()


  count.plot(kind = 'pie', explode = [0, 0.1],

              figsize = (6, 6), autopct = '%1.1f%%', shadow = True)
  plt.ylabel("Loan: Fully Paid Vs. Not Fully Paid")
  plt.legend(["Fully Paid", "Not Fully Paid"])
  plt.show()


# Visualize the proportion of borrowers
show_loan_distrib(loan_data)

loan_data.isnull().sum()

# Check column types
print(loan_data.dtypes)

encoded_loan_data = pd.get_dummies(loan_data, prefix="purpose",

                                   drop_first=True)
print(encoded_loan_data.dtypes)

from sklearn.model_selection import train_test_split
X = encoded_loan_data.drop('not.fully.paid', axis = 1)
y = encoded_loan_data['not.fully.paid']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,

                                           stratify = y, random_state=2022)

import seaborn as sa
X_train_cp = X_train.copy()
X_train_cp['not.fully.paid'] = y_train
y_0 = X_train_cp[X_train_cp['not.fully.paid'] == 0]
y_1 = X_train_cp[X_train_cp['not.fully.paid'] == 1]
y_0_undersample = y_0.sample(y_1.shape[0])
loan_data_undersample = pd.concat([y_0_undersample, y_1], axis = 0)


# Visualize the proportion of borrowers
show_loan_distrib(loan_data_undersample)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.utils import resample

# Load your data
loan_data = pd.read_csv("/content/loan_data.csv")

# Preprocess the data (example)
encoded_loan_data = pd.get_dummies(loan_data, prefix="purpose", drop_first=True)
X = encoded_loan_data.drop('not.fully.paid', axis=1)
y = encoded_loan_data['not.fully.paid']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=2022)

# Random Oversampling
X_train_combined = pd.concat([X_train, y_train], axis=1)
majority_class = X_train_combined[X_train_combined['not.fully.paid'] == 0]
minority_class = X_train_combined[X_train_combined['not.fully.paid'] == 1]

# Randomly duplicate the minority class instances
minority_upsampled = resample(minority_class,
                              replace=True,     # Sample with replacement
                              n_samples=len(majority_class),  # Match the majority class
                              random_state=2022) # Reproducible results

# Combine majority class with upsampled minority class
upsampled = pd.concat([majority_class, minority_upsampled])

# Separate back into X and y
X_train_upsampled = upsampled.drop('not.fully.paid', axis=1)
y_train_upsampled = upsampled['not.fully.paid']

# Step 1: Fit your model (example with Random Forest)
model = RandomForestClassifier(class_weight='balanced', random_state=2022)
model.fit(X_train_upsampled, y_train_upsampled)  # Use upsampled data

# Step 2: Make predictions
y_pred = model.predict(X_test)

# Step 3: Evaluate performance
# Print accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Print the classification report
report = classification_report(y_test, y_pred)
print(report)

# Optional: Print confusion matrix for more insights
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Create the correlation matrix
correlation_matrix = X_train_cp.corr()

# Step 2: Set up the matplotlib figure
plt.figure(figsize=(12, 10))

# Step 3: Create the heatmap
#sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar=True)
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='viridis', square=True, cbar=True)


# Step 4: Set titles and labels
plt.title('Feature Correlation Heatmap')
plt.show()

loan_data.describe()
# to get summary statistics of numerical features.

loan_data.info()
# to check for missing values and data types.

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Instantiate the model
model = RandomForestClassifier(random_state=2022)

# Fit the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Visualize the confusion matrix
import seaborn as sns
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()